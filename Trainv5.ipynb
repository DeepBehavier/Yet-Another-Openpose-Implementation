{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michael_zl_prime\r\n"
     ]
    }
   ],
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Credentialed Accounts\r\n",
      "ACTIVE  ACCOUNT\r\n",
      "*       312164605303-compute@developer.gserviceaccount.com\r\n",
      "\r\n",
      "To set the active account, run:\r\n",
      "    $ gcloud config set account `ACCOUNT`\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test which virtualenv running in\n",
    "import sys\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precautions to run on TPU.\n",
    "1.make sure you have a TPU, it's ON, correct version (2.x), correct IP\n",
    "2.for the checkpoints, make sure you have full scope access on the VM, service account is not enough.\n",
    "2.1.if permissions/scope have changed remove .gsutil cache 'rm -r ~/.gsutil'\n",
    "3.for the data buckets, make sure the TPU and VM have full permissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "from config import TRANSFORMED_TRAIN_ANNOTATIONS_PATH,TRANSFORMED_VALIDATION_ANNOTATIONS_PATH,IMAGE_SIZE\n",
    "from models.six_stage_linear_model import ModelMaker\n",
    "import dataset_functions\n",
    "import visualizations as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0-dev20191124'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training config, can be moved later to main config\n",
    "CACHE=False\n",
    "CACHE_RAMFS=False #uses a ramfs file to force using main memory\n",
    "BATCH_SIZE=32  #must be small if caching\n",
    "SHUFFLE=True\n",
    "PREFETCH=10  #size of prefetch size, 0 to disable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#TODO\n",
    "Dataset side\n",
    "* add apropirate settings for TFRecordDataset -V\n",
    "* cache (before transformations) just to avoid disk access (should be ~9gigs) -V\n",
    "* move cache to ramfs -V\n",
    "* add augmentation ,after cache, probably before transformations \n",
    "* add prefetch, shuffle -V \n",
    "* create validation dataset -V\n",
    "\n",
    "Compilation side\n",
    "* callbacks:\n",
    "    *tensorboard\n",
    "    *saving weights every epoch -V\n",
    "    *learning rate\n",
    "    *\n",
    "* add tensorboard callback\n",
    "\n",
    "* add hyper parameters (learning rate, learning rate decay)\n",
    "* Figure out metrics (accuracy)\n",
    "    *add recall ,mean absoulte error, and 'island' recall error\n",
    "    *sort metrics by stage\n",
    "* add validation -V\n",
    "\n",
    "All\n",
    "* add comments\n",
    "\n",
    "TPUs\n",
    "* try with TPUs -VVV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Results\n",
    "*caching seems to eat only gpu memory\n",
    "*Intersting to try a ramfs or a BytesIO object , (ramfs is probably better though as tf handles the interface)\n",
    "*This should allow to increase batch size\n",
    "-Full epoc currently is 1:15h\n",
    "TPUs\n",
    "-After figuring out TPUs, 13min epoch is achieved!\n",
    "\n",
    "-execution adjustments, batch siez, caching.\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: 10.0.3.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: 10.0.3.2:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "tpu_ip='10.0.3.2'\n",
    "# !!!MAKE SURE THE TPU ADDRESS IS CORRECT!!\n",
    "# 1.ip must be correct\n",
    "# 2.tpu must be turned on!\n",
    "# 3.version must be 'nightly-2.x'\n",
    "# 4.tpu must be reachable (check with gce netowrking/connectivity test)\n",
    "# if not this will hang\n",
    "tpu_address = 'grpc://'+tpu_ip+':8470'\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Caching using ramfs (irrelevant for tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CACHE_RAMFS:\n",
    "    !mkdir /tmp/ramdisk\n",
    "    !sudo umount /tmp/ramdisk\n",
    "    !sudo mount -t ramfs -o size=512m ramfs /tmp/ramdisk\n",
    "    !sudo chown $LOGNAME:$LOGNAME /tmp/ramdisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CACHE_RAMFS:\n",
    "    cache_loc=\"/tmp/ramdisk/cache_t\"\n",
    "    cache_v_loc=\"/tmp/ramdisk/cache_v\"\n",
    "else:\n",
    "    cache_loc=None\n",
    "    cache_v_loc=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_transformer=dataset_functions.LabelTransformer()\n",
    "@tf.function\n",
    "def make_label_tensors(elem):\n",
    "    \"\"\"Transforms a dict data element:\n",
    "    1.Read jpg to tensor \n",
    "    1.1 Resize img to correct size for network\n",
    "    2.Convert keypoints to correct form label tensor\n",
    "    3.Convert joints to correct form label tensor\n",
    "    outputs a tuple data element\"\"\"\n",
    "    \n",
    "    idd=elem['id']\n",
    "    kpt_tr=label_transformer.keypoints_spots_vmapfn(elem['kpts'])\n",
    "    paf_tr=label_transformer.joints_PAFs(elem['joints'])\n",
    "    \n",
    "    image_raw=elem[\"image_raw\"]\n",
    "    image=tf.image.decode_jpeg(image_raw,channels=3)\n",
    "    image=tf.image.convert_image_dtype(image,dtype=tf.float32)\n",
    "    image=tf.image.resize(image,IMAGE_SIZE)\n",
    "    return image,(paf_tr,kpt_tr),idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def place_training_labels(image,labels,idd):\n",
    "    \"\"\"Disterbutes labels into the correct configuration for the model, ie 4 PAF stage, 2 kpt stages\n",
    "    must match the model\"\"\"\n",
    "    paf_tr=labels[0]\n",
    "    kpt_tr=labels[1]\n",
    "    return image,(paf_tr,paf_tr,paf_tr,paf_tr,kpt_tr,kpt_tr) #this should match the model outputs, and is different for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Parse the TFrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE=56000 #exact size not critical\n",
    "DATASET_VAL_SIZE=2500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "figure out GCS storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix=TRANSFORMED_TRAIN_ANNOTATIONS_PATH.split(os.sep)[-1]\n",
    "val_prefix=TRANSFORMED_VALIDATION_ANNOTATIONS_PATH.split(os.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name=\"datasets_bucket_a\"\n",
    "gs_prefix=\"gs://\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client() #must have apropriate authenitication to work \n",
    "\n",
    "train_blobs = storage_client.list_blobs(bucket_name,prefix=train_prefix)\n",
    "val_blobs = storage_client.list_blobs(bucket_name,prefix=val_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_files_train=[gs_prefix+bucket_name+'/'+blob.name for blob in train_blobs]\n",
    "tfrecord_files_val=[gs_prefix+bucket_name+'/'+blob.name for blob in val_blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfrecord_files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(tfrecord_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_parser=dataset_functions.TFrecordParser() #used for \n",
    "\n",
    "#order of transformations is critical!\n",
    "\n",
    "#TFrecord files to raw format\n",
    "ds = tf.data.TFRecordDataset(tfrecord_files_train) #numf reads can be put here, but I don't think I/O is the bottleneck\n",
    "\n",
    "#raw format to imgs,tensors(coords kpts)\n",
    "ds=ds.map(TF_parser.read_tfrecord)\n",
    "\n",
    "#cache  ,caching is here before decompressing jpgs and label tensors (should be ~9GB) , (full dataset should be ~90, cache later if RAM aviable)\n",
    "if CACHE: ds=ds.cache(cache_loc)\n",
    "if SHUFFLE: ds=ds.shuffle(100)    \n",
    "    \n",
    "#Augmentation should be here, to operate on smaller tensors\n",
    "    \n",
    "#imgs,tensors to label_tensors (46,46,17/38)\n",
    "ds=ds.map(make_label_tensors)\n",
    "#imgs,label_tensors arrange for model outputs\n",
    "ds=ds.map(place_training_labels) \n",
    "\n",
    "#batch\n",
    "ds=ds.batch(BATCH_SIZE)\n",
    "#repeat\n",
    "ds=ds.repeat()\n",
    "#prefetch\n",
    "if PREFETCH: ds=ds.prefetch(PREFETCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_parser=dataset_functions.TFrecordParser() #used for \n",
    "\n",
    "#order of transformations is critical!\n",
    "\n",
    "#TFrecord files to raw format\n",
    "ds_v = tf.data.TFRecordDataset(tfrecord_files_val) #numf reads can be put here, but I don't think I/O is the bottleneck\n",
    "#raw format to imgs,tensors(coords kpts)\n",
    "ds_v=ds_v.map(TF_parser.read_tfrecord)   \n",
    "\n",
    "#cache  \n",
    "if CACHE: ds_v=ds_v.cache(cache_v_loc)\n",
    "    \n",
    "#imgs,tensors to label_tensors (46,46,17/38)\n",
    "ds_v=ds_v.map(make_label_tensors)\n",
    "#imgs,label_tensors arrange for model outputs\n",
    "ds_v=ds_v.map(place_training_labels) \n",
    "#batch\n",
    "ds_v=ds_v.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=next(iter(ds))\n",
    "#st\n",
    "#st_v=next(iter(ds_v))\n",
    "#v.show_pafs_kpts_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(st[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 368, 368, 3), ((None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 17), (None, 46, 46, 17))), types: (tf.float32, (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 368, 368, 3), ((None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 38), (None, 46, 46, 17), (None, 46, 46, 17))), types: (tf.float32, (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Callbacks\n",
    "**Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local dir for CPU/GPU training\n",
    "#checkpoints_dir='./checkpoints'\n",
    "#!mkdir checkpoints\n",
    "#gcs dir for TPU training\n",
    "checkpoints_dir='gs://dl_training_results/checkpoints'\n",
    "#make sure the directory exists, if not make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed271119-1313'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "t=datetime.datetime.now()\n",
    "now=t.strftime(\"%a%d%m%y-%H%M\")\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://dl_training_results/checkpoints/ModelWeights-Wed271119-1313-{epoch:04d}.ckpt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_path = checkpoints_dir+\"/ModelWeights-\"+now+\"-{epoch:04d}.ckpt\" \n",
    "checkpoints_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/test [Content-Type=application/octet-stream]...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://dl_training_results/checkpoints/test...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "#if this fails, the checkpointing won't work\n",
    "!touch /tmp/test\n",
    "!gsutil cp /tmp/test {checkpoints_dir}/test\n",
    "!gsutil rm {checkpoints_dir}/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoints_path,\n",
    "                                             save_weights_only=True,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir='gs://dl_training_results/logging/'\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(logging_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/test [Content-Type=application/octet-stream]...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://dl_training_results/logging//test...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "#if this fails, the checkpointing won't work\n",
    "!touch /tmp/test\n",
    "!gsutil cp /tmp/test {logging_dir}/test\n",
    "!gsutil rm {logging_dir}/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorBoard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir='gs://dl_training_results/tensorboard/'\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tensorboard_dir\n",
    "    ,update_freq=5000 #to update sooner than every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/test [Content-Type=application/octet-stream]...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://dl_training_results/tensorboard/test...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "#if this fails, the checkpointing won't work\n",
    "!touch /tmp/test\n",
    "!gsutil cp /tmp/test {tensorboard_dir}/test\n",
    "!gsutil rm {tensorboard_dir}/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the command to run tensorboard\n",
    "#tensorboard serve --logdir gs://dl_training_results/tensorboard --port 8889 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mse_2d_loss(y_true, y_pred):\n",
    "    pixel_losses=tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    return tf.math.reduce_mean(pixel_losses,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalogRecallError(tf.keras.metrics.Metric):\n",
    "    \"\"\"This metric returns the overlap error of the true gaussian 'islands' and the predicted ones\"\"\"\n",
    "    def __init__(self, name='analog_recall_error',thershold=0.01, **kwargs):\n",
    "        super(AnalogRecallError, self).__init__(name=name, **kwargs)\n",
    "        self.mean = self.add_weight(name='mean', initializer='zeros')\n",
    "        self.thershold=thershold\n",
    "    \n",
    "    def update_state(self, y_true, y_pred,**kwargs):        \n",
    "        true_island_sum=tf.reduce_sum(tf.where(y_true>self.thershold,y_true,0)) #get sum of the true island\n",
    "        true_island_size=tf.cast(tf.math.count_nonzero(y_true>self.thershold),dtype=tf.float32) #get size of the island   \n",
    "        mean_island_true=true_island_sum/true_island_size #average island value\n",
    "               \n",
    "        err=y_true-y_pred  #get all error\n",
    "        recall_err=tf.where(err>0,err,0)  #get only recall error, the parts where prediction is missing\n",
    "        recall_err_sum=tf.reduce_sum(recall_err)        \n",
    "        err_island_size=tf.cast(tf.math.count_nonzero(y_true>self.thershold),tf.float32)  #get size of the islands above thershold\n",
    "        \n",
    "        mean_island_recall_err=recall_err_sum/err_island_size  #mean of the error \n",
    "        \n",
    "        value=mean_island_recall_err/mean_island_true\n",
    "        self.mean.assign_add(value)\n",
    "    def result(self):\n",
    "        return self.mean\n",
    "class AnalogRecall(tf.keras.metrics.Metric):\n",
    "    \"\"\"This metric returns the overlap of the true gaussian 'islands' and the predicted ones\"\"\"\n",
    "    def __init__(self, name='analog_recall_error',thershold=0.01, **kwargs):\n",
    "        super(AnalogRecall, self).__init__(name=name, **kwargs)\n",
    "        self.mean = self.add_weight(name='mean', initializer='zeros')\n",
    "        self.thershold=thershold\n",
    "    \n",
    "    @tf.function\n",
    "    def update_state(self, y_true, y_pred,**kwargs):     \n",
    "        \n",
    "        true_island_sum=tf.reduce_sum(tf.where(y_true>self.thershold,y_true,0)) #get sum of the true island\n",
    "        true_island_size=tf.cast(tf.math.count_nonzero(y_true>self.thershold),dtype=tf.float32) #get size of the island   \n",
    "        mean_island_true=true_island_sum/true_island_size #average island value\n",
    "               \n",
    "        err=y_true-y_pred  #get all error\n",
    "        recall_err=tf.where(err>0,err,0)  #get only recall error, the parts where prediction is missing\n",
    "        recall_err_sum=tf.reduce_sum(recall_err)        \n",
    "        err_island_size=tf.cast(tf.math.count_nonzero(y_true>self.thershold),tf.float32)  #get size of the islands above thershold\n",
    "        \n",
    "        mean_island_recall_err=recall_err_sum/err_island_size  #mean of the error \n",
    "        \n",
    "        value=1-mean_island_recall_err/mean_island_true #the 1- converts it to recall accuracy onstead of err        \n",
    "        self.mean.assign_add(value)\n",
    "    def result(self):\n",
    "        return self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of <function AnalogRecall.update_state at 0x7ff2121311e0>, found return value of type <class 'tensorflow.python.framework.ops.Operation'>, which is not a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_composite\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m   1436\u001b[0m   return internal_convert_to_tensor_or_composite(\n\u001b[0;32m-> 1437\u001b[0;31m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_composite\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m         accepted_result_types=(Tensor, composite_tensor.CompositeTensor))\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_operation_conversion_error\u001b[0;34m(op, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   6530\u001b[0m                    \"(target dtype=%r, name=%r, as_ref=%r)\") %\n\u001b[0;32m-> 6531\u001b[0;31m                   (op.name, dtype, name, as_ref))\n\u001b[0m\u001b[1;32m   6532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert Operation 'PartitionedFunctionCall' to Tensor (target dtype=None, name=None, as_ref=False)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c890b48a8079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     train_model.compile(optimizer=tf.keras.optimizers.Adam()\n\u001b[1;32m     15\u001b[0m                     \u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse_2d_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                    )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mskip_target_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m           masks=self._prepare_output_masks())\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       \u001b[0;31m# Prepare sample weight modes. List with the same length as model outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[0;34m(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)\u001b[0m\n\u001b[1;32m   1968\u001b[0m           metric_results.extend(\n\u001b[1;32m   1969\u001b[0m               self._handle_per_output_metrics(self._per_output_metrics[i],\n\u001b[0;32m-> 1970\u001b[0;31m                                               target, output, output_mask))\n\u001b[0m\u001b[1;32m   1971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_weighted_and_unweighted_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreturn_weighted_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m           metric_results.extend(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[0;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[1;32m   1919\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         metric_result = training_utils.call_metric_function(\n\u001b[0;32m-> 1921\u001b[0;31m             metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[1;32m   1922\u001b[0m         \u001b[0mmetric_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcall_metric_function\u001b[0;34m(metric_fn, y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m   \u001b[0;31m# `Mean` metric only takes a single value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     return distributed_training_utils.call_replica_local_fn(\n\u001b[0;32m--> 197\u001b[0;31m         replica_local_fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mcall_replica_local_fn\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreplica_local_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplica_local_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;34m\"\"\"Updates the state of the metric in a replica-local context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2720\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2721\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2608\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    981\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0;32m--> 983\u001b[0;31m                                         expand_composites=True)\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0mcheck_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    941\u001b[0m               \u001b[0;34m\"must return zero or more Tensors; in compilation of %s, found \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m               \u001b[0;34m\"return value of type %s, which is not a Tensor.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m               (str(python_func), type(x)))\n\u001b[0m\u001b[1;32m    944\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of <function AnalogRecall.update_state at 0x7ff2121311e0>, found return value of type <class 'tensorflow.python.framework.ops.Operation'>, which is not a Tensor."
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model_maker=ModelMaker()\n",
    "    train_model,test_model=model_maker.create_models()\n",
    "    \n",
    "    #this must match the model output order\n",
    "    metrics={'stage1paf_output':  [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]\n",
    "         ,'stage2paf_output':  [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]\n",
    "         ,'stage3paf_output':  [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]\n",
    "         ,'stage4paf_output':  [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]\n",
    "         ,'stage5heatmap_output': [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]    \n",
    "         ,'stage6heatmap_output': [AnalogRecall(),tf.keras.metrics.MeanAbsoluteError()]\n",
    "        }\n",
    "    \n",
    "    train_model.compile(optimizer=tf.keras.optimizers.Adam()\n",
    "                    ,loss=mse_2d_loss\n",
    "                    ,metrics=metrics                    \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint: gs://dl_training_results/checkpoints/ModelWeights-Wed271119-1313-0001.ckpt\n"
     ]
    }
   ],
   "source": [
    "#load latest weights\n",
    "latest = tf.train.latest_checkpoint(checkpoints_dir)\n",
    "if latest:\n",
    "    print(\"Found checkpoint: %s\" % latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2a650e65fc456ebc1ab682ad4965ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Load last weights')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Load last weights'\n",
    ")\n",
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest and (load.value):\n",
    "    train_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Actually training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=int(DATASET_SIZE/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 7 steps\n",
      "Epoch 1/2\n",
      "1/7 [===>..........................] - ETA: 6:02 - loss: 0.3440 - stage1paf_output_loss: 0.0464 - stage2paf_output_loss: 0.0478 - stage3paf_output_loss: 0.0755 - stage4paf_output_loss: 0.0272 - stage5heatmap_output_loss: 0.0668 - stage6heatmap_output_loss: 0.0804 - stage1paf_output_analog_recall_error: 1.6352 - stage1paf_output_mean_absolute_error: 0.1167 - stage2paf_output_analog_recall_error: 2.3400 - stage2paf_output_mean_absolute_error: 0.1185 - stage3paf_output_analog_recall_error: 1.8509 - stage3paf_output_mean_absolute_error: 0.1365 - stage4paf_output_analog_recall_error: 1.7809 - stage4paf_output_mean_absolute_error: 0.0875 - stage5heatmap_output_analog_recall_error: 1.6615 - stage5heatmap_output_mean_absolute_error: 0.1488 - stage6heatmap_output_analog_recall_error: 2.5395 - stage6heatmap_output_mean_absolute_error: 0.1835WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.064939). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.064939). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/7 [=======>......................] - ETA: 2:35 - loss: 0.3188 - stage1paf_output_loss: 0.0265 - stage2paf_output_loss: 0.0472 - stage3paf_output_loss: 0.0567 - stage4paf_output_loss: 0.0462 - stage5heatmap_output_loss: 0.0663 - stage6heatmap_output_loss: 0.0759 - stage1paf_output_analog_recall_error: 3.1359 - stage1paf_output_mean_absolute_error: 0.0760 - stage2paf_output_analog_recall_error: 3.1956 - stage2paf_output_mean_absolute_error: 0.1034 - stage3paf_output_analog_recall_error: 2.9142 - stage3paf_output_mean_absolute_error: 0.1090 - stage4paf_output_analog_recall_error: 3.7588 - stage4paf_output_mean_absolute_error: 0.0931 - stage5heatmap_output_analog_recall_error: 3.0868 - stage5heatmap_output_mean_absolute_error: 0.1433 - stage6heatmap_output_analog_recall_error: 3.3609 - stage6heatmap_output_mean_absolute_error: 0.1528WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.603885). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.603885). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/7 [===========>..................] - ETA: 1:23 - loss: 0.2458 - stage1paf_output_loss: 0.0180 - stage2paf_output_loss: 0.0318 - stage3paf_output_loss: 0.0382 - stage4paf_output_loss: 0.0312 - stage5heatmap_output_loss: 0.0596 - stage6heatmap_output_loss: 0.0669 - stage1paf_output_analog_recall_error: 3.4472 - stage1paf_output_mean_absolute_error: 0.0524 - stage2paf_output_analog_recall_error: 3.2847 - stage2paf_output_mean_absolute_error: 0.0706 - stage3paf_output_analog_recall_error: 2.9614 - stage3paf_output_mean_absolute_error: 0.0741 - stage4paf_output_analog_recall_error: 3.9114 - stage4paf_output_mean_absolute_error: 0.0641 - stage5heatmap_output_analog_recall_error: 3.0712 - stage5heatmap_output_mean_absolute_error: 0.1238 - stage6heatmap_output_analog_recall_error: 4.0590 - stage6heatmap_output_mean_absolute_error: 0.1357WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.329276). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.329276). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/7 [========================>.....] - ETA: 10s - loss: 0.1649 - stage1paf_output_loss: 0.0094 - stage2paf_output_loss: 0.0164 - stage3paf_output_loss: 0.0195 - stage4paf_output_loss: 0.0160 - stage5heatmap_output_loss: 0.0499 - stage6heatmap_output_loss: 0.0536 - stage1paf_output_analog_recall_error: 3.6019 - stage1paf_output_mean_absolute_error: 0.0273 - stage2paf_output_analog_recall_error: 3.3257 - stage2paf_output_mean_absolute_error: 0.0367 - stage3paf_output_analog_recall_error: 2.9743 - stage3paf_output_mean_absolute_error: 0.0381 - stage4paf_output_analog_recall_error: 4.2060 - stage4paf_output_mean_absolute_error: 0.0339 - stage5heatmap_output_analog_recall_error: 3.5074 - stage5heatmap_output_mean_absolute_error: 0.0997 - stage6heatmap_output_analog_recall_error: 4.6416 - stage6heatmap_output_mean_absolute_error: 0.1067WARNING:tensorflow:5 out of the last 13 calls to <function mse_2d_loss at 0x7ff2c092a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function mse_2d_loss at 0x7ff2c092a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to gs://dl_training_results/checkpoints/ModelWeights-Wed271119-1313-0001.ckpt\n",
      "7/7 [==============================] - 137s 20s/step - loss: 0.1518 - stage1paf_output_loss: 0.0082 - stage2paf_output_loss: 0.0141 - stage3paf_output_loss: 0.0169 - stage4paf_output_loss: 0.0139 - stage5heatmap_output_loss: 0.0478 - stage6heatmap_output_loss: 0.0509 - stage1paf_output_analog_recall_error: 3.5961 - stage1paf_output_mean_absolute_error: 0.0236 - stage2paf_output_analog_recall_error: 3.3317 - stage2paf_output_mean_absolute_error: 0.0317 - stage3paf_output_analog_recall_error: 2.9671 - stage3paf_output_mean_absolute_error: 0.0329 - stage4paf_output_analog_recall_error: 4.2744 - stage4paf_output_mean_absolute_error: 0.0294 - stage5heatmap_output_analog_recall_error: 3.9228 - stage5heatmap_output_mean_absolute_error: 0.0961 - stage6heatmap_output_analog_recall_error: 5.0445 - stage6heatmap_output_mean_absolute_error: 0.1022 - val_loss: 0.0845 - val_stage1paf_output_loss: 7.7620e-04 - val_stage2paf_output_loss: 7.7671e-04 - val_stage3paf_output_loss: 7.7585e-04 - val_stage4paf_output_loss: 7.7546e-04 - val_stage5heatmap_output_loss: 0.0409 - val_stage6heatmap_output_loss: 0.0405 - val_stage1paf_output_analog_recall_error: nan - val_stage1paf_output_mean_absolute_error: 0.0014 - val_stage2paf_output_analog_recall_error: nan - val_stage2paf_output_mean_absolute_error: 0.0015 - val_stage3paf_output_analog_recall_error: nan - val_stage3paf_output_mean_absolute_error: 0.0013 - val_stage4paf_output_analog_recall_error: nan - val_stage4paf_output_mean_absolute_error: 0.0016 - val_stage5heatmap_output_analog_recall_error: nan - val_stage5heatmap_output_mean_absolute_error: 0.0785 - val_stage6heatmap_output_analog_recall_error: nan - val_stage6heatmap_output_mean_absolute_error: 0.0810\n",
      "Epoch 2/2\n",
      "1/7 [===>..........................] - ETA: 10s - loss: 0.0883 - stage1paf_output_loss: 7.8447e-04 - stage2paf_output_loss: 7.8502e-04 - stage3paf_output_loss: 7.8409e-04 - stage4paf_output_loss: 7.8380e-04 - stage5heatmap_output_loss: 0.0428 - stage6heatmap_output_loss: 0.0424 - stage1paf_output_analog_recall_error: -0.0096 - stage1paf_output_mean_absolute_error: 0.0014 - stage2paf_output_analog_recall_error: -0.0014 - stage2paf_output_mean_absolute_error: 0.0016 - stage3paf_output_analog_recall_error: -0.0098 - stage3paf_output_mean_absolute_error: 0.0014 - stage4paf_output_analog_recall_error: 0.0373 - stage4paf_output_mean_absolute_error: 0.0017 - stage5heatmap_output_analog_recall_error: 0.1655 - stage5heatmap_output_mean_absolute_error: 0.0811 - stage6heatmap_output_analog_recall_error: 0.2718 - stage6heatmap_output_mean_absolute_error: 0.0834WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.363414). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.363414). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0920 - stage1paf_output_loss: 6.8587e-04 - stage2paf_output_loss: 6.8590e-04 - stage3paf_output_loss: 6.8548e-04 - stage4paf_output_loss: 6.8668e-04 - stage5heatmap_output_loss: 0.0442 - stage6heatmap_output_loss: 0.0450 - stage1paf_output_analog_recall_error: -0.0689 - stage1paf_output_mean_absolute_error: 0.0013 - stage2paf_output_analog_recall_error: -0.0561 - stage2paf_output_mean_absolute_error: 0.0013 - stage3paf_output_analog_recall_error: -0.0691 - stage3paf_output_mean_absolute_error: 0.0012 - stage4paf_output_analog_recall_error: 0.0374 - stage4paf_output_mean_absolute_error: 0.0015 - stage5heatmap_output_analog_recall_error: 2.0278 - stage5heatmap_output_mean_absolute_error: 0.0882 - stage6heatmap_output_analog_recall_error: 1.8380 - stage6heatmap_output_mean_absolute_error: 0.0893\n",
      "Epoch 00002: saving model to gs://dl_training_results/checkpoints/ModelWeights-Wed271119-1313-0002.ckpt\n",
      "7/7 [==============================] - 54s 8s/step - loss: 0.0900 - stage1paf_output_loss: 6.8110e-04 - stage2paf_output_loss: 6.8116e-04 - stage3paf_output_loss: 6.8075e-04 - stage4paf_output_loss: 6.8182e-04 - stage5heatmap_output_loss: 0.0433 - stage6heatmap_output_loss: 0.0441 - stage1paf_output_analog_recall_error: -0.0800 - stage1paf_output_mean_absolute_error: 0.0013 - stage2paf_output_analog_recall_error: -0.0672 - stage2paf_output_mean_absolute_error: 0.0013 - stage3paf_output_analog_recall_error: -0.0802 - stage3paf_output_mean_absolute_error: 0.0012 - stage4paf_output_analog_recall_error: 0.0262 - stage4paf_output_mean_absolute_error: 0.0014 - stage5heatmap_output_analog_recall_error: 2.3257 - stage5heatmap_output_mean_absolute_error: 0.0863 - stage6heatmap_output_analog_recall_error: 1.8214 - stage6heatmap_output_mean_absolute_error: 0.0867 - val_loss: 0.0854 - val_stage1paf_output_loss: 7.7587e-04 - val_stage2paf_output_loss: 7.7611e-04 - val_stage3paf_output_loss: 7.7580e-04 - val_stage4paf_output_loss: 7.7585e-04 - val_stage5heatmap_output_loss: 0.0408 - val_stage6heatmap_output_loss: 0.0416 - val_stage1paf_output_analog_recall_error: nan - val_stage1paf_output_mean_absolute_error: 0.0013 - val_stage2paf_output_analog_recall_error: nan - val_stage2paf_output_mean_absolute_error: 0.0013 - val_stage3paf_output_analog_recall_error: nan - val_stage3paf_output_mean_absolute_error: 0.0013 - val_stage4paf_output_analog_recall_error: nan - val_stage4paf_output_mean_absolute_error: 0.0013 - val_stage5heatmap_output_analog_recall_error: nan - val_stage5heatmap_output_mean_absolute_error: 0.0783 - val_stage6heatmap_output_analog_recall_error: nan - val_stage6heatmap_output_mean_absolute_error: 0.0759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2151ba320>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit(\n",
    "    ds,epochs=2\n",
    "    ,steps_per_epoch=7\n",
    "    ,validation_data=ds_v\n",
    "    ,callbacks=[cp_callback\n",
    "                #,csv_logger\n",
    "                ,tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v.show_pafs_kpts_img(img.numpy(),paf.numpy(),kpt.numpy(),1,1) #can be used to draw the tensor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!IT IS FUCKING WORKING!!!!!!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean absolute error is probably best measure of overall error, but is bound to be very small.\n",
    "recall can work for kpts but not for PAFs, accuracy is useless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
