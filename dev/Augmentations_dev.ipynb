{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import default_config as cfg\n",
    "import remote_storage_config as storage_cfg\n",
    "\n",
    "cfg.__dict__.update(storage_cfg.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_functions\n",
    "import models.six_stage_linear_model as model\n",
    "import dataset_builder\n",
    "import utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving TFrecords from: gs://datasets_bucket_a/training\n",
      "Retrieving TFrecords from: gs://datasets_bucket_a/validation\n",
      "Found the following training TFrecords:\n",
      " gs://datasets_bucket_a/training-001.tfrecords\n",
      "gs://datasets_bucket_a/training-002.tfrecords\n",
      "gs://datasets_bucket_a/training-003.tfrecords\n",
      "gs://datasets_bucket_a/training-004.tfrecords\n",
      "gs://datasets_bucket_a/training-005.tfrecords\n",
      "gs://datasets_bucket_a/training-006.tfrecords\n",
      "gs://datasets_bucket_a/training-007.tfrecords\n",
      "gs://datasets_bucket_a/training-008.tfrecords\n",
      "gs://datasets_bucket_a/training-009.tfrecords\n",
      "gs://datasets_bucket_a/training-010.tfrecords\n",
      "gs://datasets_bucket_a/training-011.tfrecords\n",
      "gs://datasets_bucket_a/training-012.tfrecords\n",
      "gs://datasets_bucket_a/training-013.tfrecords\n",
      "gs://datasets_bucket_a/training-014.tfrecords\n",
      "gs://datasets_bucket_a/training-015.tfrecords\n",
      "gs://datasets_bucket_a/training-016.tfrecords\n",
      "gs://datasets_bucket_a/training-017.tfrecords\n",
      "gs://datasets_bucket_a/training-018.tfrecords\n",
      "gs://datasets_bucket_a/training-019.tfrecords\n",
      "gs://datasets_bucket_a/training-020.tfrecords\n",
      "gs://datasets_bucket_a/training-021.tfrecords\n",
      "gs://datasets_bucket_a/training-022.tfrecords\n",
      "gs://datasets_bucket_a/training-023.tfrecords\n",
      "gs://datasets_bucket_a/training-024.tfrecords\n",
      "gs://datasets_bucket_a/training-025.tfrecords\n",
      "gs://datasets_bucket_a/training-026.tfrecords\n",
      "gs://datasets_bucket_a/training-027.tfrecords\n",
      "gs://datasets_bucket_a/training-028.tfrecords\n",
      "gs://datasets_bucket_a/training-029.tfrecords\n",
      "gs://datasets_bucket_a/training-030.tfrecords\n",
      "gs://datasets_bucket_a/training-031.tfrecords\n",
      "gs://datasets_bucket_a/training-032.tfrecords\n",
      "gs://datasets_bucket_a/training-033.tfrecords\n",
      "gs://datasets_bucket_a/training-034.tfrecords\n",
      "gs://datasets_bucket_a/training-035.tfrecords\n",
      "gs://datasets_bucket_a/training-036.tfrecords\n",
      "gs://datasets_bucket_a/training-037.tfrecords\n",
      "gs://datasets_bucket_a/training-038.tfrecords\n",
      "gs://datasets_bucket_a/training-039.tfrecords\n",
      "gs://datasets_bucket_a/training-040.tfrecords\n",
      "gs://datasets_bucket_a/training-041.tfrecords\n",
      "gs://datasets_bucket_a/training-042.tfrecords\n",
      "gs://datasets_bucket_a/training-043.tfrecords\n",
      "gs://datasets_bucket_a/training-044.tfrecords\n",
      "gs://datasets_bucket_a/training-045.tfrecords\n",
      "gs://datasets_bucket_a/training-046.tfrecords\n",
      "gs://datasets_bucket_a/training-047.tfrecords\n",
      "gs://datasets_bucket_a/training-048.tfrecords\n",
      "gs://datasets_bucket_a/training-049.tfrecords\n",
      "gs://datasets_bucket_a/training-050.tfrecords\n",
      "gs://datasets_bucket_a/training-051.tfrecords\n",
      "gs://datasets_bucket_a/training-052.tfrecords\n",
      "gs://datasets_bucket_a/training-053.tfrecords\n",
      "gs://datasets_bucket_a/training-054.tfrecords\n",
      "gs://datasets_bucket_a/training-055.tfrecords\n",
      "gs://datasets_bucket_a/training-056.tfrecords\n",
      "gs://datasets_bucket_a/training-057.tfrecords\n",
      "Found the following validation TFrecords:\n",
      " gs://datasets_bucket_a/validation-001.tfrecords\n",
      "gs://datasets_bucket_a/validation-002.tfrecords\n",
      "gs://datasets_bucket_a/validation-003.tfrecords\n",
      "Building training dataset\n"
     ]
    }
   ],
   "source": [
    "model_ds=model.ModelDatasetComponent(cfg)\n",
    "\n",
    "tfrecord_files_train=dataset_builder.get_tfrecord_filenames(cfg.TRAIN_TFRECORDS,cfg)\n",
    "tfrecord_files_valid=dataset_builder.get_tfrecord_filenames(cfg.VALID_TFRECORDS,cfg)\n",
    "print(\"Found the following training TFrecords:\\n\",\"\\n\".join(tfrecord_files_train))\n",
    "print(\"Found the following validation TFrecords:\\n\",\"\\n\".join(tfrecord_files_valid))\n",
    "\n",
    "print(\"Building training dataset\")\n",
    "\n",
    "def build_training_ds(tfrecord_filenames: list, labels_placement_function, config) -> tf.data.Dataset:\n",
    "    \"\"\"    :param config: effective config dict\n",
    "    :param labels_placement_function: a model function, which applies the last stage of transformation to the dataset, to distribute the\n",
    "    various labels correctly according to model outputs\n",
    "    :param tfrecord_filenames: should be list of correct TFrecord filename, either local or remote (gcs, with gs:// prefix)\"\"\"\n",
    "    # TFrecord files to raw format\n",
    "    dataset_transformer = dataset_functions.DatasetTransformer(config)\n",
    "    ds = tf.data.TFRecordDataset(tfrecord_filenames)  # numf reads can be put here, but I don't think I/O is the bottleneck\n",
    "\n",
    "    # raw format to imgs,tensors(coords kpts)\n",
    "    ds = ds.map(dataset_transformer.read_tfrecord)\n",
    "\n",
    "    # cache  ,caching is here before decompressing jpgs and label tensors (should be ~9GB) , (full dataset should be ~90, cache later if RAM aviable)\n",
    "    if config.CACHE: ds = ds.cache()\n",
    "    if config.SHUFFLE: ds = ds.shuffle(100)\n",
    "\n",
    "    ds = ds.map(dataset_transformer.open_image) #jpeg to array\n",
    "    # Augmentation should be here, to operate on smaller tensors\n",
    "\n",
    "    \n",
    "    ds = ds.map(dataset_transformer.make_label_tensors) # tensors to label_tensors (46,46,17/38)\n",
    "    ds = ds.map(labels_placement_function) # imgs,label_tensors arrange for model outputs\n",
    "\n",
    "    ds = ds.batch(config.BATCH_SIZE)\n",
    "    ds = ds.repeat()\n",
    "    if config.PREFETCH: ds = ds.prefetch(config.PREFETCH)\n",
    "    return ds\n",
    "\n",
    "\n",
    "dst=build_training_ds(tfrecord_files_train,model_ds.place_training_labels,cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
