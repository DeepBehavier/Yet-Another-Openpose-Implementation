{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Yet Another OpenPose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michael_zl_prime\n",
      "                  Credentialed Accounts\n",
      "ACTIVE  ACCOUNT\n",
      "        312164605303-compute@developer.gserviceaccount.com\n",
      "*       michael.zl.prime@gmail.com\n",
      "\n",
      "To set the active account, run:\n",
      "    $ gcloud config set account `ACCOUNT`\n",
      "\n",
      "Python running from: /usr\n",
      "Current working dir /home/michael_zl_prime/project_drive/project\n"
     ]
    }
   ],
   "source": [
    "#verify user\n",
    "!whoami\n",
    "#verify user account, if running on google cloud, otherwise ignore\n",
    "!gcloud auth list\n",
    "#which Environment/virtualenv running in\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Python running from:\",sys.prefix)\n",
    "print(\"Current working dir\",os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#start tensor board\n",
    "# must run \n",
    "#/usr/local/bin/tensorboard serve --logdir gs://dl_training_results/tensorboard --port 8889 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.tpus.start) INVALID_ARGUMENT: cannot start an already running instance\r\n"
     ]
    }
   ],
   "source": [
    "#start TPU\n",
    "!gcloud compute tpus start node-1 --zone us-central1-c\n",
    "#stop TPU\n",
    "#!gcloud compute tpus stop node-1 --zone us-central1-c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import default_config as cfg\n",
    "\n",
    "#import local_storage_config as storage_cfg\n",
    "import remote_storage_config as storage_cfg\n",
    "cfg.__dict__.update(storage_cfg.__dict__)\n",
    "\n",
    "import tpu_training.TPU_config as TPU_config\n",
    "cfg.__dict__.update(TPU_config.__dict__) #comment out to disable TPU training\n",
    "cfg.RUN_NAME=\"Try_again_smallspot\" #for reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0-dev20191203\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing results bucket connectivity\n",
      "Copying file:///tmp/test [Content-Type=application/octet-stream]...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://dl_training_results/tensorboard/test...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "Copying file:///tmp/test [Content-Type=application/octet-stream]...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n",
      "Removing gs://dl_training_results/checkpoints/test...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "Testing dataset bucket connectivity\n",
      "gs://datasets_bucket_a/training-001.tfrecords\n",
      "gs://datasets_bucket_a/training-002.tfrecords\n",
      "gs://datasets_bucket_a/training-003.tfrecords\n",
      "gs://datasets_bucket_a/training-004.tfrecords\n",
      "Testing TPU connectivity\n",
      "\n",
      "Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-12 16:50 UTC\n",
      "Nmap scan report for 10.0.3.2\n",
      "Host is up (0.0016s latency).\n",
      "PORT     STATE SERVICE\n",
      "8470/tcp open  cisco-avp\n",
      "\n",
      "Nmap done: 1 IP address (1 host up) scanned in 0.04 seconds\n",
      "Trying to connect to a TPU node\n",
      "\n",
      "!!!MAKE SURE THE TPU ADDRESS IS CORRECT!!\n",
      "1.ip must be correct\n",
      "2.tpu must be turned on\n",
      "3.version must be 'nightly-2.x'\n",
      "4.tpu must be reachable (check with gce netowrking/connectivity test)\n",
      "if not this will hang!\n",
      "\n",
      "Trying to connect to: grpc://10.0.3.2:8470\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.0.3.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.0.3.2:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "if cfg.TPU_MODE:\n",
    "    print(\"Testing results bucket connectivity\")\n",
    "    !touch /tmp/test\n",
    "    !gsutil cp /tmp/test {cfg.TENSORBOARD_PATH}/test\n",
    "    !gsutil rm {cfg.TENSORBOARD_PATH}/test\n",
    "    !gsutil cp /tmp/test {cfg.CHECKPOINTS_PATH}/test\n",
    "    !gsutil rm {cfg.CHECKPOINTS_PATH}/test\n",
    "    print(\"Testing dataset bucket connectivity\")\n",
    "    !gsutil ls gs://{cfg.GCS_TFRECORDS_BUCKETNAME} | head -4\n",
    "    print(\"Testing TPU connectivity\")\n",
    "    !nmap -Pn -p8470 {cfg.TPU_IP}\n",
    "    import tpu_training.init_TPU as init_TPU\n",
    "    strategy,resolver=init_TPU.init_tpu() #This must be run before any imports!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dataset_functions\n",
    "import models.six_stage_linear_model as model\n",
    "import callbacks\n",
    "import dataset_builder\n",
    "import load_weights\n",
    "import loss_metrics\n",
    "from utils import now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import importlib as il\n",
    "# il.reload() #useful to reload any changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving TFrecords from: gs://datasets_bucket_a/training\n",
      "Retrieving TFrecords from: gs://datasets_bucket_a/validation\n",
      "Found the following training TFrecords:\n",
      " gs://datasets_bucket_a/training-001.tfrecords\n",
      "gs://datasets_bucket_a/training-002.tfrecords\n",
      "gs://datasets_bucket_a/training-003.tfrecords\n",
      "gs://datasets_bucket_a/training-004.tfrecords\n",
      "gs://datasets_bucket_a/training-005.tfrecords\n",
      "gs://datasets_bucket_a/training-006.tfrecords\n",
      "gs://datasets_bucket_a/training-007.tfrecords\n",
      "gs://datasets_bucket_a/training-008.tfrecords\n",
      "gs://datasets_bucket_a/training-009.tfrecords\n",
      "gs://datasets_bucket_a/training-010.tfrecords\n",
      "gs://datasets_bucket_a/training-011.tfrecords\n",
      "gs://datasets_bucket_a/training-012.tfrecords\n",
      "gs://datasets_bucket_a/training-013.tfrecords\n",
      "gs://datasets_bucket_a/training-014.tfrecords\n",
      "gs://datasets_bucket_a/training-015.tfrecords\n",
      "gs://datasets_bucket_a/training-016.tfrecords\n",
      "gs://datasets_bucket_a/training-017.tfrecords\n",
      "gs://datasets_bucket_a/training-018.tfrecords\n",
      "gs://datasets_bucket_a/training-019.tfrecords\n",
      "gs://datasets_bucket_a/training-020.tfrecords\n",
      "gs://datasets_bucket_a/training-021.tfrecords\n",
      "gs://datasets_bucket_a/training-022.tfrecords\n",
      "gs://datasets_bucket_a/training-023.tfrecords\n",
      "gs://datasets_bucket_a/training-024.tfrecords\n",
      "gs://datasets_bucket_a/training-025.tfrecords\n",
      "gs://datasets_bucket_a/training-026.tfrecords\n",
      "gs://datasets_bucket_a/training-027.tfrecords\n",
      "gs://datasets_bucket_a/training-028.tfrecords\n",
      "gs://datasets_bucket_a/training-029.tfrecords\n",
      "gs://datasets_bucket_a/training-030.tfrecords\n",
      "gs://datasets_bucket_a/training-031.tfrecords\n",
      "gs://datasets_bucket_a/training-032.tfrecords\n",
      "gs://datasets_bucket_a/training-033.tfrecords\n",
      "gs://datasets_bucket_a/training-034.tfrecords\n",
      "gs://datasets_bucket_a/training-035.tfrecords\n",
      "gs://datasets_bucket_a/training-036.tfrecords\n",
      "gs://datasets_bucket_a/training-037.tfrecords\n",
      "gs://datasets_bucket_a/training-038.tfrecords\n",
      "gs://datasets_bucket_a/training-039.tfrecords\n",
      "gs://datasets_bucket_a/training-040.tfrecords\n",
      "gs://datasets_bucket_a/training-041.tfrecords\n",
      "gs://datasets_bucket_a/training-042.tfrecords\n",
      "gs://datasets_bucket_a/training-043.tfrecords\n",
      "gs://datasets_bucket_a/training-044.tfrecords\n",
      "gs://datasets_bucket_a/training-045.tfrecords\n",
      "gs://datasets_bucket_a/training-046.tfrecords\n",
      "gs://datasets_bucket_a/training-047.tfrecords\n",
      "gs://datasets_bucket_a/training-048.tfrecords\n",
      "gs://datasets_bucket_a/training-049.tfrecords\n",
      "gs://datasets_bucket_a/training-050.tfrecords\n",
      "gs://datasets_bucket_a/training-051.tfrecords\n",
      "gs://datasets_bucket_a/training-052.tfrecords\n",
      "gs://datasets_bucket_a/training-053.tfrecords\n",
      "gs://datasets_bucket_a/training-054.tfrecords\n",
      "gs://datasets_bucket_a/training-055.tfrecords\n",
      "gs://datasets_bucket_a/training-056.tfrecords\n",
      "gs://datasets_bucket_a/training-057.tfrecords\n",
      "Found the following validation TFrecords:\n",
      " gs://datasets_bucket_a/validation-001.tfrecords\n",
      "gs://datasets_bucket_a/validation-002.tfrecords\n",
      "gs://datasets_bucket_a/validation-003.tfrecords\n",
      "Building training dataset\n",
      "Training dataset shape: <PrefetchDataset shapes: (((None, 368, 368, 3), (None, 46, 46, 1)), ((None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 19), (None, 46, 46, 19))), types: ((tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32))>\n",
      "Building validation dataset\n",
      "Validation dataset shape: <PrefetchDataset shapes: (((None, 368, 368, 3), (None, 46, 46, 1)), ((None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 35), (None, 46, 46, 19), (None, 46, 46, 19))), types: ((tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32))>\n"
     ]
    }
   ],
   "source": [
    "model_ds=model.ModelDatasetComponent(cfg)\n",
    "\n",
    "tfrecord_files_train=dataset_builder.get_tfrecord_filenames(cfg.TRAIN_TFRECORDS,cfg)\n",
    "tfrecord_files_valid=dataset_builder.get_tfrecord_filenames(cfg.VALID_TFRECORDS,cfg)\n",
    "print(\"Found the following training TFrecords:\\n\",\"\\n\".join(tfrecord_files_train))\n",
    "print(\"Found the following validation TFrecords:\\n\",\"\\n\".join(tfrecord_files_valid))\n",
    "\n",
    "print(\"Building training dataset\")\n",
    "dst=dataset_builder.build_training_ds(tfrecord_files_train,model_ds.place_training_labels,cfg)\n",
    "print(\"Training dataset shape:\",dst)\n",
    "print(\"Building validation dataset\")\n",
    "dsv=dataset_builder.build_validation_ds(tfrecord_files_valid,model_ds.place_training_labels,cfg)\n",
    "print(\"Validation dataset shape:\",dsv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH_STEPS = int(cfg.DATASET_SIZE / cfg.BATCH_SIZE)\n",
    "\n",
    "SHORT_EPOCH_STEPS=50 #in batches\n",
    "SHORT_TRAINING_EPOCHS=int(cfg.TRAINING_EPOCHS*(REAL_EPOCH_STEPS/SHORT_EPOCH_STEPS))\n",
    "SHORT_VALIDATION_STEPS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test element\n",
    "# dst_iter=iter(dst)\n",
    "# sample_elem=next(dst_iter)\n",
    "# print(\"Dataset shape:\",dst) #this should match the model input, and output stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#testing mask\n",
    "# sample_elem=next(dst_iter)\n",
    "# m=sample_elem[1][1][0,...,0]\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(m)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model\n",
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these checkpoints:\n",
      "0.Dont load checkpoint\n",
      "1 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp0111Wed1219-1833/-E0009.ckpt_temp_1d8239e45732435f97e3b43074192752/part-00000-of-00002\n",
      "2 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp0111Wed1219-1833/-E0009.ckpt_temp_1d8239e45732435f97e3b43074192752/part-00001-of-00002\n",
      "3 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp0111Wed1219-1842/-E0001.ckpt\n",
      "4 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp0111Wed1219-1842/-E0002.ckpt\n",
      "5 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp0111Wed1219-1842/-E0003.ckpt\n",
      "6 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint11Wed1219-1917/-E0001.ckpt\n",
      "7 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint11Wed1219-1917/-E0002.ckpt\n",
      "8 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint11Wed1219-1917/-E0003.ckpt\n",
      "9 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint11Wed1219-1917/-E0004.ckpt\n",
      "10 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nobn-11Wed1219-2050/-E0001.ckpt\n",
      "11 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nobn-11Wed1219-2050/-E0002.ckpt\n",
      "12 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nobn-11Wed1219-2050/-E0003.ckpt\n",
      "13 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nobn-11Wed1219-2050/-E0004.ckpt\n",
      "14 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nobn-11Wed1219-2050/-E0005.ckpt\n",
      "15 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nofinalbn-11Wed1219-2011/-E0001.ckpt\n",
      "16 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nofinalbn-11Wed1219-2011/-E0002.ckpt\n",
      "17 .gs://dl_training_results/checkpoints/Full_model_2_2augs_dp01_15joint_nofinalbn-11Wed1219-2011/-E0003.ckpt\n",
      "18 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0001.ckpt\n",
      "19 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0002.ckpt\n",
      "20 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0003.ckpt\n",
      "21 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0004.ckpt\n",
      "22 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0005.ckpt\n",
      "23 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0006.ckpt\n",
      "24 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0007.ckpt\n",
      "25 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0008.ckpt\n",
      "26 .gs://dl_training_results/checkpoints/Full_model_2augs_dp11Wed1219-1624/-E0009.ckpt\n",
      "27 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0001.ckpt\n",
      "28 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0002.ckpt\n",
      "29 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0003.ckpt\n",
      "30 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0004.ckpt\n",
      "31 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0005.ckpt\n",
      "32 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0006.ckpt\n",
      "33 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0007.ckpt\n",
      "34 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0008.ckpt\n",
      "35 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0009.ckpt\n",
      "36 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0010.ckpt\n",
      "37 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0011.ckpt\n",
      "38 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0012.ckpt\n",
      "39 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0013.ckpt\n",
      "40 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0014.ckpt\n",
      "41 .gs://dl_training_results/checkpoints/no_frills_smaller_spot12Thu1219-1628/-E0015.ckpt\n",
      "Please select checkpoint, or 0 to continue without loading:0\n"
     ]
    }
   ],
   "source": [
    "if cfg.ASK_FOR_CHECKPOINTS:\n",
    "    checkpoint,starting_epoch=load_weights.checkpoints_prompt(cfg)\n",
    "else:\n",
    "    checkpoint=None\n",
    "    starting_epoch=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_maker=model.ModelMaker(cfg) #must be outside scope to keep the graph clean\n",
    "tf.keras.backend.clear_session() #to clean to backaend from the imported model\n",
    "def define():\n",
    "    train_model,test_model=model_maker.create_models()\n",
    "    \n",
    "#     if cfg.INCLUDE_MASK:\n",
    "#         losses=[loss_metrics.MaskedMeanAbsoluteError()\n",
    "#                 ,loss_metrics.MaskedMeanAbsoluteError()\n",
    "#                 ,loss_metrics.MaskedMeanAbsoluteError()\n",
    "#                 ,loss_metrics.MaskedMeanAbsoluteError()\n",
    "#                 ,loss_metrics.MaskedMeanSquaredError()\n",
    "#                 ,loss_metrics.MaskedMeanSquaredError()]\n",
    "                      \n",
    "#     else:\n",
    "#         raise NotImplementedError       \n",
    "    \n",
    "    #this must match the model output order\n",
    "#     metrics=[\n",
    "#           []\n",
    "#          ,[]\n",
    "#          ,[]\n",
    "#          ,[]\n",
    "#          ,[tf.keras.metrics.MeanAbsoluteError()]    \n",
    "#          ,[tf.keras.metrics.MeanAbsoluteError()]\n",
    "#         ]\n",
    "    \n",
    "    train_model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(cfg.BASE_LEARNING_RATE)                   \n",
    "                    ,loss=loss_metrics.MaskedMeanSquaredError()\n",
    "                    ,loss_weights=[10,10,10,10,0.2,0.2]\n",
    "                    #,metrics=metrics                           \n",
    "                   )\n",
    "    return train_model,test_model\n",
    "\n",
    "if cfg.TPU_MODE:\n",
    "    with strategy.scope():\n",
    "        train_model,test_model=define()\n",
    "        if (checkpoint):\n",
    "            train_model.load_weights(checkpoint)\n",
    "else:\n",
    "    train_model,test_model=define()\n",
    "    if (checkpoint):\n",
    "        train_model.load_weights(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_callbacks=[\n",
    "    callbacks.make_LRscheduler_callback(cfg.LEARNING_RATE_SCHEDUELE)\n",
    "    ,callbacks.PrintLR()\n",
    "    ,tf.keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "if cfg.SAVE_CHECKPOINTS:all_callbacks+=[callbacks.make_checkpoint_callback(cfg)]\n",
    "if cfg.SAVE_TENSORBOARD:all_callbacks+=[callbacks.make_tensorboard_callback(cfg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "#run to clean tensorboard results\n",
    "#!gsutil -m rm -r {cfg.TENSORBOARD_PATH}/*\n",
    "#!gsutil -m rm -r {cfg.CHECKPOINTS_PATH}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "Actually training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 5 steps\n",
      "\n",
      "Learning rate for epoch 0 is 0.0010000000474974513\n",
      "Epoch 1/874\n",
      " 1/50 [..............................] - ETA: 2:24:26 - loss: 24.7140 - s1pafs_output_loss: 0.4868 - s2pafs_output_loss: 0.7308 - s3pafs_output_loss: 0.5889 - s4pafs_output_loss: 0.6566 - s5kpts_output_loss: 0.1960 - s6kpts_output_loss: 0.2152WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.056211). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.056211). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 [============================>.] - ETA: 4s - loss: 2.2822 - s1pafs_output_loss: 0.0600 - s2pafs_output_loss: 0.0598 - s3pafs_output_loss: 0.0522 - s4pafs_output_loss: 0.0554 - s5kpts_output_loss: 0.0224 - s6kpts_output_loss: 0.0236\n",
      "Epoch 00001: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0001.ckpt\n",
      "50/50 [==============================] - 283s 6s/step - loss: 2.2423 - s1pafs_output_loss: 0.0589 - s2pafs_output_loss: 0.0587 - s3pafs_output_loss: 0.0513 - s4pafs_output_loss: 0.0544 - s5kpts_output_loss: 0.0224 - s6kpts_output_loss: 0.0236 - val_loss: 3226565529.6000 - val_s1pafs_output_loss: 7139.6235 - val_s2pafs_output_loss: 1263310.8750 - val_s3pafs_output_loss: 319118912.0000 - val_s4pafs_output_loss: 2267207.7500 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "Epoch 2/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2414 - s1pafs_output_loss: 0.0058 - s2pafs_output_loss: 0.0059 - s3pafs_output_loss: 0.0058 - s4pafs_output_loss: 0.0058 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00002: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0002.ckpt\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.2411 - s1pafs_output_loss: 0.0058 - s2pafs_output_loss: 0.0059 - s3pafs_output_loss: 0.0058 - s4pafs_output_loss: 0.0058 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 6819.7584 - val_s1pafs_output_loss: 9.1686 - val_s2pafs_output_loss: 73.0580 - val_s3pafs_output_loss: 599.0252 - val_s4pafs_output_loss: 0.7233 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "Epoch 3/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2283 - s1pafs_output_loss: 0.0054 - s2pafs_output_loss: 0.0056 - s3pafs_output_loss: 0.0056 - s4pafs_output_loss: 0.0055 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00003: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0003.ckpt\n",
      "50/50 [==============================] - 89s 2s/step - loss: 0.2279 - s1pafs_output_loss: 0.0054 - s2pafs_output_loss: 0.0056 - s3pafs_output_loss: 0.0056 - s4pafs_output_loss: 0.0055 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 20.7050 - val_s1pafs_output_loss: 0.3453 - val_s2pafs_output_loss: 0.7848 - val_s3pafs_output_loss: 0.9245 - val_s4pafs_output_loss: 0.0152 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "Epoch 4/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2267 - s1pafs_output_loss: 0.0054 - s2pafs_output_loss: 0.0058 - s3pafs_output_loss: 0.0055 - s4pafs_output_loss: 0.0053 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00004: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0004.ckpt\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.2269 - s1pafs_output_loss: 0.0054 - s2pafs_output_loss: 0.0058 - s3pafs_output_loss: 0.0055 - s4pafs_output_loss: 0.0053 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.9452 - val_s1pafs_output_loss: 0.0241 - val_s2pafs_output_loss: 0.0421 - val_s3pafs_output_loss: 0.0200 - val_s4pafs_output_loss: 0.0075 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 4 is 0.0010000000474974513\n",
      "Epoch 5/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2186 - s1pafs_output_loss: 0.0052 - s2pafs_output_loss: 0.0054 - s3pafs_output_loss: 0.0053 - s4pafs_output_loss: 0.0053 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00005: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0005.ckpt\n",
      "50/50 [==============================] - 88s 2s/step - loss: 0.2193 - s1pafs_output_loss: 0.0053 - s2pafs_output_loss: 0.0054 - s3pafs_output_loss: 0.0053 - s4pafs_output_loss: 0.0053 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2613 - val_s1pafs_output_loss: 0.0065 - val_s2pafs_output_loss: 0.0066 - val_s3pafs_output_loss: 0.0060 - val_s4pafs_output_loss: 0.0062 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 5 is 0.0010000000474974513\n",
      "Epoch 6/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2144 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0052 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00006: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0006.ckpt\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.2141 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0052 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2330 - val_s1pafs_output_loss: 0.0057 - val_s2pafs_output_loss: 0.0055 - val_s3pafs_output_loss: 0.0056 - val_s4pafs_output_loss: 0.0058 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 6 is 0.0010000000474974513\n",
      "Epoch 7/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2133 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00007: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0007.ckpt\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.2137 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0052 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2249 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0056 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 7 is 0.0010000000474974513\n",
      "Epoch 8/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2120 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00008: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0008.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.2119 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2236 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 8 is 0.0010000000474974513\n",
      "Epoch 9/874\n",
      "49/50 [============================>.] - ETA: 1s - loss: 0.2118 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0051 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00009: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0009.ckpt\n",
      "50/50 [==============================] - 127s 3s/step - loss: 0.2122 - s1pafs_output_loss: 0.0051 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0051 - s4pafs_output_loss: 0.0051 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2241 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0055 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 9 is 0.0010000000474974513\n",
      "Epoch 10/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2076 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00010: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0010.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 56s 1s/step - loss: 0.2081 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.2267 - val_s1pafs_output_loss: 0.0057 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0055 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 10 is 0.0010000000474974513\n",
      "Epoch 11/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2177 - s1pafs_output_loss: 0.0052 - s2pafs_output_loss: 0.0055 - s3pafs_output_loss: 0.0052 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183\n",
      "Epoch 00011: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0011.ckpt\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.2175 - s1pafs_output_loss: 0.0052 - s2pafs_output_loss: 0.0055 - s3pafs_output_loss: 0.0052 - s4pafs_output_loss: 0.0052 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183 - val_loss: 0.2256 - val_s1pafs_output_loss: 0.0056 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0055 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 11 is 0.0010000000474974513\n",
      "Epoch 12/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2056 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00012: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0012.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.2057 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2254 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0055 - val_s4pafs_output_loss: 0.0055 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 12 is 0.0010000000474974513\n",
      "Epoch 13/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2044 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0049 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00013: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0013.ckpt\n",
      "50/50 [==============================] - 88s 2s/step - loss: 0.2045 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0049 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2245 - val_s1pafs_output_loss: 0.0055 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 13 is 0.0010000000474974513\n",
      "Epoch 14/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2067 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00014: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0014.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.2064 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0050 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2266 - val_s1pafs_output_loss: 0.0055 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0055 - val_s4pafs_output_loss: 0.0055 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 14 is 0.0010000000474974513\n",
      "Epoch 15/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2061 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0049 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00015: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0015.ckpt\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.2060 - s1pafs_output_loss: 0.0050 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0050 - s4pafs_output_loss: 0.0049 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.2239 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0055 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 15 is 0.0010000000474974513\n",
      "Epoch 16/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2007 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00016: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0016.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.2007 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.2216 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 16 is 0.0010000000474974513\n",
      "Epoch 17/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2020 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00017: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0017.ckpt\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.2022 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2245 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0055 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 17 is 0.0010000000474974513\n",
      "Epoch 18/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2029 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00018: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0018.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.2026 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2319 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0063 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 18 is 0.0010000000474974513\n",
      "Epoch 19/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2021 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00019: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0019.ckpt\n",
      "50/50 [==============================] - 87s 2s/step - loss: 0.2020 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.2223 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0054 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate for epoch 19 is 0.0010000000474974513\n",
      "Epoch 20/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2036 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0050 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183\n",
      "Epoch 00020: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0020.ckpt\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.2041 - s1pafs_output_loss: 0.0049 - s2pafs_output_loss: 0.0051 - s3pafs_output_loss: 0.0049 - s4pafs_output_loss: 0.0048 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183 - val_loss: 0.2288 - val_s1pafs_output_loss: 0.0055 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0059 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 20 is 0.0010000000474974513\n",
      "Epoch 21/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1958 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0047 - s4pafs_output_loss: 0.0047 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00021: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0021.ckpt\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.1959 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0047 - s4pafs_output_loss: 0.0047 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.2236 - val_s1pafs_output_loss: 0.0054 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0057 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 21 is 0.0010000000474974513\n",
      "Epoch 22/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1942 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0046 - s4pafs_output_loss: 0.0046 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175\n",
      "Epoch 00022: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0022.ckpt\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.1938 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0046 - s4pafs_output_loss: 0.0046 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175 - val_loss: 0.2213 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0054 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 22 is 0.0010000000474974513\n",
      "Epoch 23/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1988 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0048 - s4pafs_output_loss: 0.0047 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00023: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0023.ckpt\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.1987 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0047 - s4pafs_output_loss: 0.0047 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.2160 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0052 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 23 is 0.0010000000474974513\n",
      "Epoch 24/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1968 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0047 - s4pafs_output_loss: 0.0046 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00024: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0024.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1970 - s1pafs_output_loss: 0.0048 - s2pafs_output_loss: 0.0049 - s3pafs_output_loss: 0.0047 - s4pafs_output_loss: 0.0047 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.2227 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0057 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 24 is 0.0010000000474974513\n",
      "Epoch 25/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1919 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0046 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00025: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0025.ckpt\n",
      "50/50 [==============================] - 88s 2s/step - loss: 0.1922 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0046 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.2188 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 25 is 0.0010000000474974513\n",
      "Epoch 26/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1910 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00026: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0026.ckpt\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.1909 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.2102 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0051 - val_s3pafs_output_loss: 0.0050 - val_s4pafs_output_loss: 0.0050 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 26 is 0.0010000000474974513\n",
      "Epoch 27/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1902 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00027: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0027.ckpt\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.1902 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0044 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2056 - val_s1pafs_output_loss: 0.0051 - val_s2pafs_output_loss: 0.0051 - val_s3pafs_output_loss: 0.0048 - val_s4pafs_output_loss: 0.0049 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 27 is 0.0010000000474974513\n",
      "Epoch 28/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1926 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00028: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0028.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1929 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0048 - s3pafs_output_loss: 0.0046 - s4pafs_output_loss: 0.0045 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.2178 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 28 is 0.0010000000474974513\n",
      "Epoch 29/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1906 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0044 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00029: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0029.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 95s 2s/step - loss: 0.1905 - s1pafs_output_loss: 0.0047 - s2pafs_output_loss: 0.0047 - s3pafs_output_loss: 0.0045 - s4pafs_output_loss: 0.0044 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.2266 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0052 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0060 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 29 is 0.0010000000474974513\n",
      "Epoch 30/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1820 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0043 - s4pafs_output_loss: 0.0043 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00030: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0030.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1819 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0043 - s4pafs_output_loss: 0.0043 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.2206 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0054 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 30 is 0.0010000000474974513\n",
      "Epoch 31/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1806 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175\n",
      "Epoch 00031: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0031.ckpt\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.1805 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175 - val_loss: 0.2221 - val_s1pafs_output_loss: 0.0053 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0053 - val_s4pafs_output_loss: 0.0056 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 31 is 0.0010000000474974513\n",
      "Epoch 32/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1848 - s1pafs_output_loss: 0.0046 - s2pafs_output_loss: 0.0045 - s3pafs_output_loss: 0.0043 - s4pafs_output_loss: 0.0043 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182\n",
      "Epoch 00032: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0032.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.1841 - s1pafs_output_loss: 0.0046 - s2pafs_output_loss: 0.0045 - s3pafs_output_loss: 0.0043 - s4pafs_output_loss: 0.0043 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.2160 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0052 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0052 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 32 is 0.0010000000474974513\n",
      "Epoch 33/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1794 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00033: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0033.ckpt\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.1791 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0044 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.2163 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 33 is 0.0010000000474974513\n",
      "Epoch 34/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1756 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0043 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00034: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0034.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1752 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0042 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.2167 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0052 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 34 is 0.0010000000474974513\n",
      "Epoch 35/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1746 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0042 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00035: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0035.ckpt\n",
      "50/50 [==============================] - 102s 2s/step - loss: 0.1747 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0042 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2168 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0053 - val_s3pafs_output_loss: 0.0051 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 35 is 0.0010000000474974513\n",
      "Epoch 36/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1780 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0043 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00036: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0036.ckpt\n",
      "50/50 [==============================] - 68s 1s/step - loss: 0.1775 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0043 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2256 - val_s1pafs_output_loss: 0.0051 - val_s2pafs_output_loss: 0.0051 - val_s3pafs_output_loss: 0.0065 - val_s4pafs_output_loss: 0.0051 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 36 is 0.0010000000474974513\n",
      "Epoch 37/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1791 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0043 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183\n",
      "Epoch 00037: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0037.ckpt\n",
      "50/50 [==============================] - 100s 2s/step - loss: 0.1793 - s1pafs_output_loss: 0.0045 - s2pafs_output_loss: 0.0043 - s3pafs_output_loss: 0.0042 - s4pafs_output_loss: 0.0042 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183 - val_loss: 0.2187 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0052 - val_s3pafs_output_loss: 0.0052 - val_s4pafs_output_loss: 0.0055 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 37 is 0.0010000000474974513\n",
      "Epoch 38/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1745 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0042 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00038: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0038.ckpt\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.1741 - s1pafs_output_loss: 0.0044 - s2pafs_output_loss: 0.0042 - s3pafs_output_loss: 0.0041 - s4pafs_output_loss: 0.0041 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.2157 - val_s1pafs_output_loss: 0.0052 - val_s2pafs_output_loss: 0.0052 - val_s3pafs_output_loss: 0.0051 - val_s4pafs_output_loss: 0.0053 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate for epoch 38 is 0.0010000000474974513\n",
      "Epoch 39/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1673 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00039: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0039.ckpt\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.1670 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.2034 - val_s1pafs_output_loss: 0.0050 - val_s2pafs_output_loss: 0.0050 - val_s3pafs_output_loss: 0.0048 - val_s4pafs_output_loss: 0.0048 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 39 is 0.0010000000474974513\n",
      "Epoch 40/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1678 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00040: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0040.ckpt\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.1676 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.2031 - val_s1pafs_output_loss: 0.0051 - val_s2pafs_output_loss: 0.0050 - val_s3pafs_output_loss: 0.0047 - val_s4pafs_output_loss: 0.0048 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 40 is 0.0005000000237487257\n",
      "Epoch 41/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1683 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00041: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0041.ckpt\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.1686 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1913 - val_s1pafs_output_loss: 0.0048 - val_s2pafs_output_loss: 0.0047 - val_s3pafs_output_loss: 0.0044 - val_s4pafs_output_loss: 0.0044 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 41 is 0.0005000000237487257\n",
      "Epoch 42/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1656 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00042: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0042.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1650 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1855 - val_s1pafs_output_loss: 0.0046 - val_s2pafs_output_loss: 0.0045 - val_s3pafs_output_loss: 0.0043 - val_s4pafs_output_loss: 0.0043 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 42 is 0.0005000000237487257\n",
      "Epoch 43/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1623 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00043: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0043.ckpt\n",
      "50/50 [==============================] - 100s 2s/step - loss: 0.1623 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1823 - val_s1pafs_output_loss: 0.0046 - val_s2pafs_output_loss: 0.0045 - val_s3pafs_output_loss: 0.0042 - val_s4pafs_output_loss: 0.0042 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 43 is 0.0005000000237487257\n",
      "Epoch 44/874\n",
      "49/50 [============================>.] - ETA: 1s - loss: 0.1624 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00044: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0044.ckpt\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.1624 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1876 - val_s1pafs_output_loss: 0.0047 - val_s2pafs_output_loss: 0.0046 - val_s3pafs_output_loss: 0.0043 - val_s4pafs_output_loss: 0.0044 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 44 is 0.0005000000237487257\n",
      "Epoch 45/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1635 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00045: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0045.ckpt\n",
      "50/50 [==============================] - 101s 2s/step - loss: 0.1637 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1844 - val_s1pafs_output_loss: 0.0047 - val_s2pafs_output_loss: 0.0044 - val_s3pafs_output_loss: 0.0043 - val_s4pafs_output_loss: 0.0043 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 45 is 0.0005000000237487257\n",
      "Epoch 46/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1666 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182\n",
      "Epoch 00046: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0046.ckpt\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.1668 - s1pafs_output_loss: 0.0042 - s2pafs_output_loss: 0.0040 - s3pafs_output_loss: 0.0039 - s4pafs_output_loss: 0.0039 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.1724 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 46 is 0.0005000000237487257\n",
      "Epoch 47/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1626 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00047: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0047.ckpt\n",
      "50/50 [==============================] - 104s 2s/step - loss: 0.1624 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1862 - val_s1pafs_output_loss: 0.0047 - val_s2pafs_output_loss: 0.0045 - val_s3pafs_output_loss: 0.0043 - val_s4pafs_output_loss: 0.0044 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 47 is 0.0005000000237487257\n",
      "Epoch 48/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1611 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00048: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0048.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 61s 1s/step - loss: 0.1613 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1720 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 48 is 0.0005000000237487257\n",
      "Epoch 49/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1584 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175\n",
      "Epoch 00049: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0049.ckpt\n",
      "50/50 [==============================] - 105s 2s/step - loss: 0.1583 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175 - val_loss: 0.1765 - val_s1pafs_output_loss: 0.0044 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0041 - val_s4pafs_output_loss: 0.0041 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 49 is 0.0005000000237487257\n",
      "Epoch 50/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1626 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00050: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0050.ckpt\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.1623 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1749 - val_s1pafs_output_loss: 0.0044 - val_s2pafs_output_loss: 0.0043 - val_s3pafs_output_loss: 0.0041 - val_s4pafs_output_loss: 0.0041 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 50 is 0.0005000000237487257\n",
      "Epoch 51/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1581 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00051: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0051.ckpt\n",
      "50/50 [==============================] - 101s 2s/step - loss: 0.1581 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1896 - val_s1pafs_output_loss: 0.0048 - val_s2pafs_output_loss: 0.0046 - val_s3pafs_output_loss: 0.0044 - val_s4pafs_output_loss: 0.0044 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 51 is 0.0005000000237487257\n",
      "Epoch 52/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1570 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00052: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0052.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.1572 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1717 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 52 is 0.0005000000237487257\n",
      "Epoch 53/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1595 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00053: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0053.ckpt\n",
      "50/50 [==============================] - 112s 2s/step - loss: 0.1593 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1735 - val_s1pafs_output_loss: 0.0044 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 53 is 0.0005000000237487257\n",
      "Epoch 54/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1597 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00054: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0054.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1598 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1701 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 54 is 0.0005000000237487257\n",
      "Epoch 55/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1605 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182\n",
      "Epoch 00055: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0055.ckpt\n",
      "50/50 [==============================] - 110s 2s/step - loss: 0.1602 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.1658 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0040 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 55 is 0.0005000000237487257\n",
      "Epoch 56/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1626 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00056: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0056.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1625 - s1pafs_output_loss: 0.0041 - s2pafs_output_loss: 0.0039 - s3pafs_output_loss: 0.0038 - s4pafs_output_loss: 0.0038 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1778 - val_s1pafs_output_loss: 0.0045 - val_s2pafs_output_loss: 0.0043 - val_s3pafs_output_loss: 0.0041 - val_s4pafs_output_loss: 0.0042 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 56 is 0.0005000000237487257\n",
      "Epoch 57/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1546 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175\n",
      "Epoch 00057: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0057.ckpt\n",
      "50/50 [==============================] - 115s 2s/step - loss: 0.1547 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0175 - s6kpts_output_loss: 0.0175 - val_loss: 0.1708 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate for epoch 57 is 0.0005000000237487257\n",
      "Epoch 58/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1575 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00058: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0058.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1578 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1696 - val_s1pafs_output_loss: 0.0044 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0039 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 58 is 0.0005000000237487257\n",
      "Epoch 59/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1577 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00059: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0059.ckpt\n",
      "50/50 [==============================] - 115s 2s/step - loss: 0.1571 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1710 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0039 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 59 is 0.0005000000237487257\n",
      "Epoch 60/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1549 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00060: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0060.ckpt\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.1548 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1693 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0039 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 60 is 0.0005000000237487257\n",
      "Epoch 61/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1540 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00061: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0061.ckpt\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.1543 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1646 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0040 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 61 is 0.0005000000237487257\n",
      "Epoch 62/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1547 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00062: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0062.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1544 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1721 - val_s1pafs_output_loss: 0.0044 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0039 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 62 is 0.0005000000237487257\n",
      "Epoch 63/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1545 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00063: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0063.ckpt\n",
      "50/50 [==============================] - 108s 2s/step - loss: 0.1547 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1665 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0040 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 63 is 0.0005000000237487257\n",
      "Epoch 64/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1590 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183\n",
      "Epoch 00064: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0064.ckpt\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.1589 - s1pafs_output_loss: 0.0040 - s2pafs_output_loss: 0.0038 - s3pafs_output_loss: 0.0037 - s4pafs_output_loss: 0.0037 - s5kpts_output_loss: 0.0183 - s6kpts_output_loss: 0.0183 - val_loss: 0.1719 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0041 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0041 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 64 is 0.0005000000237487257\n",
      "Epoch 65/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1533 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00065: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0065.ckpt\n",
      "50/50 [==============================] - 117s 2s/step - loss: 0.1529 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1719 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0040 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 65 is 0.0005000000237487257\n",
      "Epoch 66/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1511 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00066: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0066.ckpt\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.1512 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1620 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 66 is 0.0005000000237487257\n",
      "Epoch 67/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1528 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00067: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0067.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 114s 2s/step - loss: 0.1527 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1635 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 67 is 0.0005000000237487257\n",
      "Epoch 68/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1524 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00068: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0068.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1524 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1638 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 68 is 0.0005000000237487257\n",
      "Epoch 69/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1512 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00069: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0069.ckpt\n",
      "50/50 [==============================] - 109s 2s/step - loss: 0.1511 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1624 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 69 is 0.0005000000237487257\n",
      "Epoch 70/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1492 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00070: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0070.ckpt\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.1492 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1602 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 70 is 0.0005000000237487257\n",
      "Epoch 71/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1519 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00071: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0071.ckpt\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.1523 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1671 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0040 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 71 is 0.0005000000237487257\n",
      "Epoch 72/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1495 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00072: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0072.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1493 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1591 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 72 is 0.0005000000237487257\n",
      "Epoch 73/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1551 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182\n",
      "Epoch 00073: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0073.ckpt\n",
      "50/50 [==============================] - 117s 2s/step - loss: 0.1548 - s1pafs_output_loss: 0.0039 - s2pafs_output_loss: 0.0037 - s3pafs_output_loss: 0.0036 - s4pafs_output_loss: 0.0036 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.1623 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0038 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 73 is 0.0005000000237487257\n",
      "Epoch 74/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1506 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00074: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0074.ckpt\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.1507 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1714 - val_s1pafs_output_loss: 0.0043 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0038 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 74 is 0.0005000000237487257\n",
      "Epoch 75/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1481 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00075: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0075.ckpt\n",
      "50/50 [==============================] - 117s 2s/step - loss: 0.1479 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1600 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 75 is 0.0005000000237487257\n",
      "Epoch 76/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1508 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00076: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0076.ckpt\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.1508 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1684 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0040 - val_s3pafs_output_loss: 0.0039 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate for epoch 76 is 0.0005000000237487257\n",
      "Epoch 77/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1493 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00077: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0077.ckpt\n",
      "50/50 [==============================] - 118s 2s/step - loss: 0.1493 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1613 - val_s1pafs_output_loss: 0.0041 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 77 is 0.0005000000237487257\n",
      "Epoch 78/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1458 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00078: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0078.ckpt\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1463 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1659 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0039 - val_s3pafs_output_loss: 0.0040 - val_s4pafs_output_loss: 0.0039 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 78 is 0.0005000000237487257\n",
      "Epoch 79/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1462 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00079: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0079.ckpt\n",
      "50/50 [==============================] - 136s 3s/step - loss: 0.1461 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1582 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 79 is 0.0005000000237487257\n",
      "Epoch 80/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1488 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00080: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0080.ckpt\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1485 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1606 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 80 is 0.0005000000237487257\n",
      "Epoch 81/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1470 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00081: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0081.ckpt\n",
      "50/50 [==============================] - 119s 2s/step - loss: 0.1473 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1568 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 81 is 0.0005000000237487257\n",
      "Epoch 82/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1511 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182\n",
      "Epoch 00082: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0082.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1508 - s1pafs_output_loss: 0.0038 - s2pafs_output_loss: 0.0036 - s3pafs_output_loss: 0.0035 - s4pafs_output_loss: 0.0035 - s5kpts_output_loss: 0.0182 - s6kpts_output_loss: 0.0182 - val_loss: 0.1592 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 82 is 0.0005000000237487257\n",
      "Epoch 83/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1456 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00083: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0083.ckpt\n",
      "50/50 [==============================] - 121s 2s/step - loss: 0.1454 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1563 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 83 is 0.0005000000237487257\n",
      "Epoch 84/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1454 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00084: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0084.ckpt\n",
      "50/50 [==============================] - 68s 1s/step - loss: 0.1453 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1567 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 84 is 0.0005000000237487257\n",
      "Epoch 85/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1455 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00085: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0085.ckpt\n",
      "50/50 [==============================] - 124s 2s/step - loss: 0.1455 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1547 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 85 is 0.0005000000237487257\n",
      "Epoch 86/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1452 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00086: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0086.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 58s 1s/step - loss: 0.1450 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1556 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 86 is 0.0005000000237487257\n",
      "Epoch 87/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1459 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00087: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0087.ckpt\n",
      "50/50 [==============================] - 133s 3s/step - loss: 0.1457 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180 - val_loss: 0.1580 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 87 is 0.0005000000237487257\n",
      "Epoch 88/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1423 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00088: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0088.ckpt\n",
      "50/50 [==============================] - 64s 1s/step - loss: 0.1422 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1542 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 88 is 0.0005000000237487257\n",
      "Epoch 89/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1435 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00089: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0089.ckpt\n",
      "50/50 [==============================] - 118s 2s/step - loss: 0.1436 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1516 - val_s1pafs_output_loss: 0.0038 - val_s2pafs_output_loss: 0.0036 - val_s3pafs_output_loss: 0.0035 - val_s4pafs_output_loss: 0.0035 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 89 is 0.0005000000237487257\n",
      "Epoch 90/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1471 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00090: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0090.ckpt\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.1470 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1576 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 90 is 0.0005000000237487257\n",
      "Epoch 91/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1475 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00091: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0091.ckpt\n",
      "50/50 [==============================] - 129s 3s/step - loss: 0.1473 - s1pafs_output_loss: 0.0037 - s2pafs_output_loss: 0.0035 - s3pafs_output_loss: 0.0034 - s4pafs_output_loss: 0.0034 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1556 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 91 is 0.0005000000237487257\n",
      "Epoch 92/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1423 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00092: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0092.ckpt\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.1424 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1563 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 92 is 0.0005000000237487257\n",
      "Epoch 93/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1424 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176\n",
      "Epoch 00093: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0093.ckpt\n",
      "50/50 [==============================] - 131s 3s/step - loss: 0.1426 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0176 - s6kpts_output_loss: 0.0176 - val_loss: 0.1595 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0037 - val_s4pafs_output_loss: 0.0037 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 93 is 0.0005000000237487257\n",
      "Epoch 94/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1443 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179\n",
      "Epoch 00094: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0094.ckpt\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.1442 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179 - val_loss: 0.1750 - val_s1pafs_output_loss: 0.0042 - val_s2pafs_output_loss: 0.0042 - val_s3pafs_output_loss: 0.0041 - val_s4pafs_output_loss: 0.0043 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 94 is 0.0005000000237487257\n",
      "Epoch 95/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1437 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00095: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0095.ckpt\n",
      "50/50 [==============================] - 131s 3s/step - loss: 0.1436 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1530 - val_s1pafs_output_loss: 0.0038 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0035 - val_s4pafs_output_loss: 0.0035 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate for epoch 95 is 0.0005000000237487257\n",
      "Epoch 96/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1405 - s1pafs_output_loss: 0.0035 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0032 - s4pafs_output_loss: 0.0032 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00096: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0096.ckpt\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1402 - s1pafs_output_loss: 0.0035 - s2pafs_output_loss: 0.0033 - s3pafs_output_loss: 0.0032 - s4pafs_output_loss: 0.0032 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1564 - val_s1pafs_output_loss: 0.0040 - val_s2pafs_output_loss: 0.0038 - val_s3pafs_output_loss: 0.0036 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 96 is 0.0005000000237487257\n",
      "Epoch 97/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1410 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0032 - s4pafs_output_loss: 0.0032 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178\n",
      "Epoch 00097: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0097.ckpt\n",
      "50/50 [==============================] - 141s 3s/step - loss: 0.1410 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0032 - s4pafs_output_loss: 0.0032 - s5kpts_output_loss: 0.0178 - s6kpts_output_loss: 0.0178 - val_loss: 0.1524 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0036 - val_s3pafs_output_loss: 0.0035 - val_s4pafs_output_loss: 0.0035 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 97 is 0.0005000000237487257\n",
      "Epoch 98/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1425 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177\n",
      "Epoch 00098: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0098.ckpt\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1419 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0177 - s6kpts_output_loss: 0.0177 - val_loss: 0.1544 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0037 - val_s3pafs_output_loss: 0.0035 - val_s4pafs_output_loss: 0.0036 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 98 is 0.0005000000237487257\n",
      "Epoch 99/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1437 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0180 - s6kpts_output_loss: 0.0180\n",
      "Epoch 00099: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0099.ckpt\n",
      "50/50 [==============================] - 123s 2s/step - loss: 0.1441 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1500 - val_s1pafs_output_loss: 0.0038 - val_s2pafs_output_loss: 0.0036 - val_s3pafs_output_loss: 0.0034 - val_s4pafs_output_loss: 0.0034 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 99 is 0.0005000000237487257\n",
      "Epoch 100/874\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1434 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181\n",
      "Epoch 00100: saving model to gs://dl_training_results/checkpoints/Try_again_smallspot12Thu1219-1651/-E0100.ckpt\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.1434 - s1pafs_output_loss: 0.0036 - s2pafs_output_loss: 0.0034 - s3pafs_output_loss: 0.0033 - s4pafs_output_loss: 0.0033 - s5kpts_output_loss: 0.0181 - s6kpts_output_loss: 0.0181 - val_loss: 0.1528 - val_s1pafs_output_loss: 0.0039 - val_s2pafs_output_loss: 0.0036 - val_s3pafs_output_loss: 0.0035 - val_s4pafs_output_loss: 0.0035 - val_s5kpts_output_loss: 0.0188 - val_s6kpts_output_loss: 0.0188\n",
      "\n",
      "Learning rate for epoch 100 is 0.0003000000142492354\n",
      "Epoch 101/874\n",
      "26/50 [==============>...............] - ETA: 22s - loss: 0.1397 - s1pafs_output_loss: 0.0035 - s2pafs_output_loss: 0.0033 - s3pafs_output_loss: 0.0032 - s4pafs_output_loss: 0.0032 - s5kpts_output_loss: 0.0179 - s6kpts_output_loss: 0.0179"
     ]
    }
   ],
   "source": [
    "train_history=train_model.fit(\n",
    "    dst\n",
    "    ,epochs=SHORT_TRAINING_EPOCHS\n",
    "    ,steps_per_epoch=SHORT_EPOCH_STEPS\n",
    "    ,validation_steps=SHORT_VALIDATION_STEPS\n",
    "    ,validation_data=dsv\n",
    "    ,callbacks=all_callbacks\n",
    "    ,initial_epoch=starting_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tmp_path='gs://dl_training_results/tmp/tensorflow/temp_weights'\n",
    "train_model.save_weights(tmp_path)\n",
    "\n",
    "cpu_train_model,cpu_test_model=define()\n",
    "\n",
    "cpu_train_model.load_weights(tmp_path)\n",
    "cpu_test_model.load_weights(tmp_path)\n",
    "\n",
    "cpu_test_model.save(cfg.MODELS_PATH+\"/test_\"+now()+cfg.RUN_NAME) \n",
    "cpu_train_model.save(cfg.MODELS_PATH+\"/train_\"+now()+cfg.RUN_NAME) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#shut down TPU\n",
    "!gcloud compute tpus stop node-1 --zone us-central1-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#shut down this host\n",
    "!gcloud compute instances stop instance-1 --zone us-central1-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
